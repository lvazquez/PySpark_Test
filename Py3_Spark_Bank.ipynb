{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "bank_txt = spark.sparkContext.textFile(\"/data/examples/bank.csv\")\n",
    "\n",
    "bank_df = bank_txt.map(lambda s: re.sub(r'(?:^\\\"|\\\"$)', '', s))\\\n",
    "    .map(lambda s: re.split('\\\"?;\\\"?', s))\\\n",
    "    .filter(lambda s: s[0] != \"age\")\\\n",
    "    .map(lambda s: [int(s[0])] + s[1:4] + [int(s[5])]).toDF(['age', 'job', 'marital', 'education', 'balance'])\n",
    "bank_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df2 = spark.read.csv(\"/data/examples/bank.csv\",\n",
    "                         inferSchema=True, header=True, sep=\";\", quote='\"')\n",
    "bank_df2.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = bank_df2.select(['age', 'job', 'marital', 'education', 'balance'])\n",
    "bank_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.createOrReplaceTempView('bank_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_pdf = spark.sql('''SELECT education, marital, count(*) AS count FROM bank_view\n",
    "WHERE education != 'unknown' GROUP BY education,marital''').toPandas()\n",
    "em_pdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = em_pdf.pivot(index='education', columns='marital', values='count')\n",
    "pdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pdf.plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/data/examples/bank.csv\", header=True, sep=';', \n",
    "                      mode=\"DROPMALFORMED\", inferSchema=True)\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"default.bank\");\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(spark.catalog.listTables(\"default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = spark.read.table(\"bank\")\n",
    "bank_jobs = bank_df.groupBy(\"job\").count()\n",
    "bank_jobs.createOrReplaceTempView(\"bank_jobs\")\n",
    "jobs_pd = spark.sql(\"select * from bank_jobs order by count desc limit 10\").toPandas()\n",
    "jobs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_pd.plot(kind='bar', x='job', y='count', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
