{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6e59b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH: /opt/conda/bin:/usr/lib64/qt-3.3/bin:/opt/conda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\n",
      "PYTHONPATH: /opt/conda/lib/python3.7/site-packages:/usr/hdp/current/spark2-client/python:/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip\n",
      "\n",
      "Spark: 2.3.2.3.1.0.0-78\n",
      "Python: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://agesic-en01.agesic.datacenterantel.uy:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.0.0-78</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "\n",
    "print(\"PATH: {}\".format(os.environ['PATH']))\n",
    "print(\"PYTHONPATH: {}\".format(os.environ['PYTHONPATH']))\n",
    "print(\"\")\n",
    "print(\"Spark: {}\".format(spark.version))\n",
    "print(\"Python: {}\".format(sys.version))\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64b487",
   "metadata": {},
   "source": [
    "## Import PyDeequ and init PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f814f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baz</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b    c\n",
       "0  foo  1  5.0\n",
       "1  bar  2  6.0\n",
       "2  baz  3  NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import pydeequ\n",
    "\n",
    "df = spark.sparkContext.parallelize([\n",
    "            Row(a=\"foo\", b=1, c=5),\n",
    "            Row(a=\"bar\", b=2, c=6),\n",
    "            Row(a=\"baz\", b=3, c=None)]).toDF()\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2314d5",
   "metadata": {},
   "source": [
    "## Example Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4eba7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>b</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity instance          name  value\n",
       "0  Dataset        *          Size    3.0\n",
       "1   Column        b  Completeness    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "analyzer = AnalysisRunner(spark).onData(df).addAnalyzer(Size()).addAnalyzer(Completeness(\"b\"))\n",
    "analysisResult = analyzer.run()\n",
    "\n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f769a",
   "metadata": {},
   "source": [
    "## Example Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b280b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:05:37 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a => StandardProfiles for column: a: {\n",
      "    \"completeness\": 1.0,\n",
      "    \"approximateNumDistinctValues\": 3,\n",
      "    \"dataType\": \"String\",\n",
      "    \"isDataTypeInferred\": false,\n",
      "    \"typeCounts\": {\n",
      "        \"Boolean\": 0,\n",
      "        \"Fractional\": 0,\n",
      "        \"Integral\": 0,\n",
      "        \"Unknown\": 0,\n",
      "        \"String\": 3\n",
      "    },\n",
      "    \"histogram\": [\n",
      "        [\n",
      "            \"baz\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"foo\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"bar\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ]\n",
      "    ]\n",
      "}\n",
      "b => NumericProfiles for column: b: {\n",
      "    \"completeness\": 1.0,\n",
      "    \"approximateNumDistinctValues\": 3,\n",
      "    \"dataType\": \"Integral\",\n",
      "    \"isDataTypeInferred\": false,\n",
      "    \"typeCounts\": {},\n",
      "    \"histogram\": [\n",
      "        [\n",
      "            \"1\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"2\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"3\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ]\n",
      "    ],\n",
      "    \"kll\": \"None\",\n",
      "    \"mean\": 2.0,\n",
      "    \"maximum\": 3.0,\n",
      "    \"minimum\": 1.0,\n",
      "    \"sum\": 6.0,\n",
      "    \"stdDev\": 0.816496580927726,\n",
      "    \"approxPercentiles\": []\n",
      "}\n",
      "c => NumericProfiles for column: c: {\n",
      "    \"completeness\": 0.6666666666666666,\n",
      "    \"approximateNumDistinctValues\": 2,\n",
      "    \"dataType\": \"Integral\",\n",
      "    \"isDataTypeInferred\": false,\n",
      "    \"typeCounts\": {},\n",
      "    \"histogram\": [\n",
      "        [\n",
      "            \"5\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"NullValue\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ],\n",
      "        [\n",
      "            \"6\",\n",
      "            1,\n",
      "            0.3333333333333333\n",
      "        ]\n",
      "    ],\n",
      "    \"kll\": \"None\",\n",
      "    \"mean\": 5.5,\n",
      "    \"maximum\": 6.0,\n",
      "    \"minimum\": 5.0,\n",
      "    \"sum\": 11.0,\n",
      "    \"stdDev\": 0.5,\n",
      "    \"approxPercentiles\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.profiles import *\n",
    "\n",
    "profiler = ColumnProfilerRunner(spark).onData(df)\n",
    "result = profiler.run()\n",
    "\n",
    "for col, profile in result.profiles.items():\n",
    "    print(f\"{col} => {profile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8913f7",
   "metadata": {},
   "source": [
    "## Example Constraint Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4377a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'constraint_name': 'CompletenessConstraint(Completeness(b,None))', 'column_name': 'b', 'current_value': 'Completeness: 1.0', 'description': \"'b' is not null\", 'suggesting_rule': 'CompleteIfCompleteRule()', 'rule_description': 'If a column is complete in the sample, we suggest a NOT NULL constraint', 'code_for_constraint': '.isComplete(\"b\")'}, {'constraint_name': \"ComplianceConstraint(Compliance('b' has no negative values,b >= 0,None))\", 'column_name': 'b', 'current_value': 'Minimum: 1.0', 'description': \"'b' has no negative values\", 'suggesting_rule': 'NonNegativeNumbersRule()', 'rule_description': 'If we see only non-negative numbers in a column, we suggest a corresponding constraint', 'code_for_constraint': '.isNonNegative(\"b\")'}, {'constraint_name': 'UniquenessConstraint(Uniqueness(List(b),None))', 'column_name': 'b', 'current_value': 'ApproxDistinctness: 1.0', 'description': \"'b' is unique\", 'suggesting_rule': 'UniqueIfApproximatelyUniqueRule()', 'rule_description': 'If the ratio of approximate num distinct values in a column is close to the number of records (within the error of the HLL sketch), we suggest a UNIQUE constraint', 'code_for_constraint': '.isUnique(\"b\")'}, {'constraint_name': 'CompletenessConstraint(Completeness(a,None))', 'column_name': 'a', 'current_value': 'Completeness: 1.0', 'description': \"'a' is not null\", 'suggesting_rule': 'CompleteIfCompleteRule()', 'rule_description': 'If a column is complete in the sample, we suggest a NOT NULL constraint', 'code_for_constraint': '.isComplete(\"a\")'}, {'constraint_name': 'UniquenessConstraint(Uniqueness(List(a),None))', 'column_name': 'a', 'current_value': 'ApproxDistinctness: 1.0', 'description': \"'a' is unique\", 'suggesting_rule': 'UniqueIfApproximatelyUniqueRule()', 'rule_description': 'If the ratio of approximate num distinct values in a column is close to the number of records (within the error of the HLL sketch), we suggest a UNIQUE constraint', 'code_for_constraint': '.isUnique(\"a\")'}, {'constraint_name': \"ComplianceConstraint(Compliance('c' has no negative values,c >= 0,None))\", 'column_name': 'c', 'current_value': 'Minimum: 5.0', 'description': \"'c' has no negative values\", 'suggesting_rule': 'NonNegativeNumbersRule()', 'rule_description': 'If we see only non-negative numbers in a column, we suggest a corresponding constraint', 'code_for_constraint': '.isNonNegative(\"c\")'}, {'constraint_name': 'CompletenessConstraint(Completeness(c,None))', 'column_name': 'c', 'current_value': 'Completeness: 0.6666666666666666', 'description': \"'c' has less than 87% missing values\", 'suggesting_rule': 'RetainCompletenessRule()', 'rule_description': 'If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness', 'code_for_constraint': '.hasCompleteness(\"c\", lambda x: x >= 0.13, \"It should be above 0.13!\")'}]\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.suggestions import *\n",
    "\n",
    "csrunner = ConstraintSuggestionRunner(spark).onData(df).addConstraintRule(DEFAULT())\n",
    "suggestionResult = csrunner.run()\n",
    "\n",
    "# Constraint Suggestions in JSON format\n",
    "print(suggestionResult['constraint_suggestions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb3563",
   "metadata": {},
   "source": [
    "## Example Constraint Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c93e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Callback server started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 794bbe7c-6ab6-45aa-9165-3a84095ff496\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>check_level</th>\n",
       "      <th>check_status</th>\n",
       "      <th>constraint</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>constraint_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>SizeConstraint(Size(None))</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>MinimumConstraint(Minimum(b,None))</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 1.0 does not meet the constraint requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>UniquenessConstraint(Uniqueness(List(a),None))</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>ComplianceConstraint(Compliance(b is non-negat...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>CompletenessConstraint(Completeness(c,None))</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Warning</td>\n",
       "      <td>ComplianceConstraint(Compliance(a contained in...</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          check check_level check_status  \\\n",
       "0  Review Check     Warning      Warning   \n",
       "1  Review Check     Warning      Warning   \n",
       "2  Review Check     Warning      Warning   \n",
       "3  Review Check     Warning      Warning   \n",
       "4  Review Check     Warning      Warning   \n",
       "5  Review Check     Warning      Warning   \n",
       "\n",
       "                                          constraint constraint_status  \\\n",
       "0                         SizeConstraint(Size(None))           Success   \n",
       "1                 MinimumConstraint(Minimum(b,None))           Failure   \n",
       "2     UniquenessConstraint(Uniqueness(List(a),None))           Success   \n",
       "3  ComplianceConstraint(Compliance(b is non-negat...           Success   \n",
       "4       CompletenessConstraint(Completeness(c,None))           Failure   \n",
       "5  ComplianceConstraint(Compliance(a contained in...           Success   \n",
       "\n",
       "                                  constraint_message  \n",
       "0                                                     \n",
       "1  Value: 1.0 does not meet the constraint requir...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Value: 0.6666666666666666 does not meet the co...  \n",
       "5                                                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"Review Check\")\n",
    "\n",
    "checkCond = check.hasSize(lambda x: x >= 3)\\\n",
    "    .hasMin(\"b\", lambda x: x == 0)\\\n",
    "    .isUnique(\"a\").isNonNegative(\"b\").isComplete(\"c\")\\\n",
    "    .isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\"])\n",
    "\n",
    "verificator = VerificationSuite(spark).onData(df).addCheck(checkCond)\n",
    "checkResult = verificator.run()\n",
    "\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e7aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
